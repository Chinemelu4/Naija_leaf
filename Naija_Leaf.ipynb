{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRt8ZHv46vl1"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import keras\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img , img_to_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmbPUCpX77YN"
   },
   "outputs": [],
   "source": [
    "tf.keras.applications.inception_v3.preprocess_input\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0VK2n-VUGM57"
   },
   "source": [
    "**STAGE 1**\n",
    "\n",
    "*I built the base model using Kera's inception_v3 model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAtVMMZC6dCe"
   },
   "outputs": [],
   "source": [
    "base_model=tf.keras.applications.inception_v3.InceptionV3(input_shape=(256,256,3),\n",
    "    include_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--iarEodGTts"
   },
   "source": [
    " This is a non-trainable model.\n",
    " \n",
    "I am not training any layers, I will just use the outputs of the base model and add to our actual layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU6_psNh8tUi"
   },
   "outputs": [],
   "source": [
    " for layer in base_model.layers:\n",
    "  layer.trainable= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDCcrYzf95H6"
   },
   "outputs": [],
   "source": [
    "X= Flatten()(base_model.output)\n",
    "X= Dense(units=5, activation= 'sigmoid')(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEGoIiPiHcPT"
   },
   "source": [
    "I will now create our actual model using Adam's optimizer and binary_cross entropy as our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCkU4WjSHoHK"
   },
   "outputs": [],
   "source": [
    "# Final model\n",
    "model=Model(base_model.input , X)\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer= 'adam',loss= keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "#summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "poRJtp-S-fw7"
   },
   "outputs": [],
   "source": [
    "## Use Data generator to carry out our image processing\n",
    "#My google drive which has already been uploaded to my colab directory has a leaf image folder containing the five different leave types in their seperate folders  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rknkPU_c_zOK"
   },
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(featurewise_center= True, rotation_range=0.4, \n",
    "                                 width_shift_range=0.3, \n",
    "                                 horizontal_flip=True, \n",
    "                                 preprocessing_function= preprocess_input ,\n",
    "                                  zoom_range=0.4, \n",
    "                                 shear_range=0.4)\n",
    "\n",
    "train_data=train_datagen.flow_from_directory(directory=\"/content/drive/MyDrive/leaves_images\", \n",
    "                                             target_size=(256,256),\n",
    "                                             batch_size=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76YksSTSBnX6"
   },
   "outputs": [],
   "source": [
    "train_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dzacb4VF1di5"
   },
   "outputs": [],
   "source": [
    "t_img , label= train_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlOlXVxW1l4i"
   },
   "outputs": [],
   "source": [
    "t_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhESi4mXH-mV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lf7s3Gl-Estd"
   },
   "outputs": [],
   "source": [
    "def plotImages(img_arr , label):\n",
    "  \"\"\"\n",
    "  input: image array\n",
    "  output: plot images\n",
    "  \"\"\"\n",
    "\n",
    "  for idx , img in enumerate( img_arr):\n",
    "\n",
    "    if idx <= 10 :\n",
    "      plt.figure(figsize=(5,5))\n",
    "      plt.imshow(img)\n",
    "      plt.title(img.shape)\n",
    "      plt.axis=False\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2w6uCkDqF4eK"
   },
   "outputs": [],
   "source": [
    "plotImages(t_img , label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qkmCJFDF_cF"
   },
   "outputs": [],
   "source": [
    "#tRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oTPPbA7GwMi"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "mc= ModelCheckpoint(filepath=\"./best_model.h5\", \n",
    "                    monitor=\"accuracy\", \n",
    "                    verbose=1, \n",
    "                    save_best_only=True)\n",
    "\n",
    "es= EarlyStopping(monitor= \"accuracy\",\n",
    "                  min_delta= 0.01,\n",
    "                  patience=5,\n",
    "                  verbose=1)\n",
    "\n",
    "cb=[mc,es] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wrso2zP8JCoo"
   },
   "outputs": [],
   "source": [
    "his =model.fit_generator(train_data, \n",
    "                         steps_per_epoch=10, \n",
    "                         epochs=30, \n",
    "                         callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9Aqa40NJcN7"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model= load_model(\"/content/drive/MyDrive/ML_models/best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qLvQkq1RK4IQ"
   },
   "outputs": [],
   "source": [
    "h= his.history\n",
    "h.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9vpvWRsKsuJ"
   },
   "source": [
    "I plotted a chart of the loss and model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9Xv3-XNLKe_"
   },
   "outputs": [],
   "source": [
    "plt.plot(h['loss'])\n",
    "plt.plot(h['accuracy'])\n",
    "\n",
    "plt.title('LOSS vs ACC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImhImabTLqbE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Mg7NuhHMRpu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YD7E7ZExMWAi"
   },
   "outputs": [],
   "source": [
    "#Validation of model with a sample picture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dxk5IqyHNZNt"
   },
   "outputs": [],
   "source": [
    "path=\"/content/drive/MyDrive/Test_image/download (7).jpg\"\n",
    "img= load_img(path, target_size=(256,256))\n",
    "\n",
    "i= img_to_array(img)\n",
    "\n",
    "i=preprocess_input(i)\n",
    "\n",
    "input_arr=np.array([i])\n",
    "input_arr.shape\n",
    "\n",
    "pred=np.argmax(model.predict(input_arr))\n",
    "y=model.predict_proba(input_arr)  \n",
    "\n",
    "if pred == 0:\n",
    "  print (\"Afang leaf\")\n",
    "elif pred==1:\n",
    "  \n",
    "  print (\"Bitterleaf\")  \n",
    "elif pred==2:\n",
    "  \n",
    "  print (\"Oha leaf\")\n",
    "elif pred==3:\n",
    "  \n",
    "  print (\"Pumpkin Leaf\")\n",
    "else:\n",
    "  print (\"Waterleaf\")\n",
    "\n",
    "plt.imshow(input_arr[0])\n",
    "plt.title(\"input image\")\n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Naija Leaf.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
